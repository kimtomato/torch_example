{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5RYHywGJvYZVHMzXC9XEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimtomato/torch_example/blob/main/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XOR 해결 - MLP"
      ],
      "metadata": {
        "id": "7aFayznVu1c7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r50SSQuluzk-",
        "outputId": "680d64e7-29bf-4d9d-dc00-784a15ab8137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7273974418640137\n",
            "100 0.6931475400924683\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "#XOR에 대한 입력 출력 \n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
        "\n",
        "linear = nn.Linear(2,1, bias=True)\n",
        "sigmoid = nn.Sigmoid()\n",
        "model = nn.Sequential(linear,sigmoid).to(device)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for step in range(10001): \n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\n",
        "        print(step, cost.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation & 다층 perceptron 구현 "
      ],
      "metadata": {
        "id": "hTAnXcS9wGs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "hHWb9qhGviz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2,10, bias=True), #input_layer=2, hidden =10\n",
        "    nn.Sigmoid(), #activation F\n",
        "    nn.Linear(10,10, bias=True),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10, bias=True),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,1,bias=True),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1) \n",
        "\n",
        "for epoch in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    # forward 연산\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmoPZUuAyJEH",
        "outputId": "f05340a0-debf-4a43-9ab0-cbef7e9cb459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6948983669281006\n",
            "100 0.6931558847427368\n",
            "200 0.6931535005569458\n",
            "300 0.6931513547897339\n",
            "400 0.6931492686271667\n",
            "500 0.6931473016738892\n",
            "600 0.6931453943252563\n",
            "700 0.6931434869766235\n",
            "800 0.6931415796279907\n",
            "900 0.6931397914886475\n",
            "1000 0.6931380033493042\n",
            "1100 0.6931362152099609\n",
            "1200 0.6931343078613281\n",
            "1300 0.6931324005126953\n",
            "1400 0.6931304931640625\n",
            "1500 0.6931284666061401\n",
            "1600 0.6931264400482178\n",
            "1700 0.6931242942810059\n",
            "1800 0.6931220293045044\n",
            "1900 0.6931196451187134\n",
            "2000 0.6931171417236328\n",
            "2100 0.6931145191192627\n",
            "2200 0.6931116580963135\n",
            "2300 0.6931085586547852\n",
            "2400 0.6931051015853882\n",
            "2500 0.6931014657020569\n",
            "2600 0.6930974721908569\n",
            "2700 0.6930930018424988\n",
            "2800 0.6930880546569824\n",
            "2900 0.6930825114250183\n",
            "3000 0.6930763125419617\n",
            "3100 0.6930692791938782\n",
            "3200 0.6930611729621887\n",
            "3300 0.6930519342422485\n",
            "3400 0.6930411458015442\n",
            "3500 0.6930283904075623\n",
            "3600 0.6930133104324341\n",
            "3700 0.6929951906204224\n",
            "3800 0.6929729580879211\n",
            "3900 0.6929453015327454\n",
            "4000 0.6929103136062622\n",
            "4100 0.6928650140762329\n",
            "4200 0.6928046941757202\n",
            "4300 0.6927220225334167\n",
            "4400 0.6926040649414062\n",
            "4500 0.6924278736114502\n",
            "4600 0.692147970199585\n",
            "4700 0.6916664838790894\n",
            "4800 0.6907395124435425\n",
            "4900 0.6886203289031982\n",
            "5000 0.6820820569992065\n",
            "5100 0.647254467010498\n",
            "5200 0.44952040910720825\n",
            "5300 0.041330933570861816\n",
            "5400 0.009731853380799294\n",
            "5500 0.005032628774642944\n",
            "5600 0.003295110072940588\n",
            "5700 0.002415277296677232\n",
            "5800 0.0018910184735432267\n",
            "5900 0.001545755541883409\n",
            "6000 0.0013024783693253994\n",
            "6100 0.001122470130212605\n",
            "6200 0.0009842305444180965\n",
            "6300 0.0008749595144763589\n",
            "6400 0.0007865644874982536\n",
            "6500 0.0007136859931051731\n",
            "6600 0.0006526226061396301\n",
            "6700 0.000600747880525887\n",
            "6800 0.0005562114529311657\n",
            "6900 0.0005175513215363026\n",
            "7000 0.0004836485313717276\n",
            "7100 0.0004538019420579076\n",
            "7200 0.0004272509249858558\n",
            "7300 0.00040348825859837234\n",
            "7400 0.00038217095425352454\n",
            "7500 0.00036286652903072536\n",
            "7600 0.0003453810350038111\n",
            "7700 0.00032938653021119535\n",
            "7800 0.0003147636307403445\n",
            "7900 0.00030134833650663495\n",
            "8000 0.00028899149037897587\n",
            "8100 0.00027755898190662265\n",
            "8200 0.0002669314562808722\n",
            "8300 0.00025710894260555506\n",
            "8400 0.0002479125396348536\n",
            "8500 0.00023934218916110694\n",
            "8600 0.00023130852787289768\n",
            "8700 0.00022378168068826199\n",
            "8800 0.00021671691501978785\n",
            "8900 0.00021006952738389373\n",
            "9000 0.0002038097009062767\n",
            "9100 0.0001978629152290523\n",
            "9200 0.00019227384473197162\n",
            "9300 0.0001869679836090654\n",
            "9400 0.00018191552953794599\n",
            "9500 0.00017716118600219488\n",
            "9600 0.00017261551693081856\n",
            "9700 0.00016829342348501086\n",
            "9800 0.0001641949056647718\n",
            "9900 0.00016023052739910781\n",
            "10000 0.0001565046259202063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
        "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
        "    print('실제값(Y): ', Y.cpu().numpy())\n",
        "    print('정확도(Accuracy): ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7mB6B-szC_8",
        "outputId": "a11c3e35-949b-4295-f358-705bd6562150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 출력값(Hypothesis):  [[1.1169227e-04]\n",
            " [9.9982882e-01]\n",
            " [9.9984241e-01]\n",
            " [1.8534942e-04]]\n",
            "모델의 예측값(Predicted):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "실제값(Y):  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy):  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DNN으로 손글씨 분류\n",
        "- MNIST와 다른 데이터\n",
        "- 0~15의 명암을 가지는 8*8=64 해상도 이미지"
      ],
      "metadata": {
        "id": "Km3dodWazLcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "metadata": {
        "id": "fGWOvDeTzLvj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.images[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZVg9j7SzvPU",
        "outputId": "2ecb8432-3b4e-442d-b773-78fa62ed71f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  0. 12. 13.  5.  0.  0.]\n",
            " [ 0.  0.  0. 11. 16.  9.  0.  0.]\n",
            " [ 0.  0.  3. 15. 16.  6.  0.  0.]\n",
            " [ 0.  7. 15. 16. 16.  2.  0.  0.]\n",
            " [ 0.  0.  1. 16. 16.  3.  0.  0.]\n",
            " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
            " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
            " [ 0.  0.  0. 11. 16. 10.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.target[1])\n",
        "print(len(digits.images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PtTvxNTzzMW",
        "outputId": "39d131e6-7302-494e-fc0b-52becb9bc096"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = digits.data\n",
        "Y = digits.target"
      ],
      "metadata": {
        "id": "nGcoNDfpz68v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim \n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(64,32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32,16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16,10)\n",
        ")"
      ],
      "metadata": {
        "id": "Fnt6e2qRBasb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "Y = torch.tensor(Y, dtype=torch.int64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUm6XxzICB_3",
        "outputId": "05c98bd3-9ea6-406f-b8be-906c8d7b1180"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-ec09ccdb9262>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X, dtype=torch.float32)\n",
            "<ipython-input-12-ec09ccdb9262>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y = torch.tensor(Y, dtype=torch.int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "losses = []\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = model(X)\n",
        "    cost = loss_fn(pred, Y)\n",
        "\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "     print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            i, 100, cost.item()\n",
        "        ))\n",
        "\n",
        "    losses.append(cost.item())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2Bww_vwCPcv",
        "outputId": "955eff91-24c6-433b-edc1-e6d4fc57e1a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 2.360586\n",
            "Epoch   10/100 Cost: 1.812495\n",
            "Epoch   20/100 Cost: 1.417901\n",
            "Epoch   30/100 Cost: 1.078911\n",
            "Epoch   40/100 Cost: 0.816139\n",
            "Epoch   50/100 Cost: 0.627071\n",
            "Epoch   60/100 Cost: 0.487348\n",
            "Epoch   70/100 Cost: 0.384294\n",
            "Epoch   80/100 Cost: 0.307657\n",
            "Epoch   90/100 Cost: 0.251665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DNN으로 MNIST 분류하기 "
      ],
      "metadata": {
        "id": "tLVPogTvrkVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.datasets import fetch_openml \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)"
      ],
      "metadata": {
        "id": "DGEoLaq3C8e4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist.target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Mjc0QEPr8IX",
        "outputId": "43a01e77-9e9e-448c-9a20-92bc54224bb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist.target = mnist.target.astype(np.int8)\n",
        "mnist.target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4yhN826sCK0",
        "outputId": "52a865d6-b691-48cf-f8d5-9f3ee9107297"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = mnist.data / 255  #0~1 사이값으로 정규화\n",
        "y = mnist.target"
      ],
      "metadata": {
        "id": "wk3ViRQYsWQS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, y_test = train_test_split(X,y,test_size = 1/7, random_state=0)\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "Y_train = torch.Tensor(Y_train)\n",
        "y_test = torch.Tensor(y_test.values)\n"
      ],
      "metadata": {
        "id": "o3blRtrcscq2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds_train = TensorDataset(X_train, Y_train)\n",
        "ds_test = TensorDataset(X_test, y_test)\n",
        "\n",
        "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
        "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "e9BswS_vs72O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('fc1', nn.Linear(28*28*1, 100))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('fc2', nn.Linear(100, 100))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('fc3', nn.Linear(100, 10))\n",
        "\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOktMuPStK6O",
        "outputId": "4f904633-f2ac-4fb5-f3a6-b00be6ec974f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "loss_F = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "Yq1QU-hZumcb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train() #train mode\n",
        "\n",
        "    for data, targets in loader_train:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(data)\n",
        "        loss = loss_F(pred,targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"epoch{}：완료\\n\".format(epoch))\n",
        "\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()  # inference mode\n",
        "    correct = 0\n",
        "\n",
        "    \n",
        "    with torch.no_grad():  # inference 과정에는 미분이 필요X\n",
        "        for data, targets in loader_test:\n",
        "\n",
        "            outputs = model(data) \n",
        "\n",
        "            # 추론 계산\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
        "            correct += predicted.eq(targets.data.view_as(predicted)).sum()  \n",
        "\n",
        "  \n",
        "    data_num = len(loader_test.dataset)  \n",
        "    print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct,\n",
        "                                                   data_num, 100. * correct / data_num))\n"
      ],
      "metadata": {
        "id": "QFjy8Qxou0O8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Q7VdmKwBZ6",
        "outputId": "5c6ce9be-e32f-44ed-ad34-9d2329185ed7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "테스트 데이터에서 예측 정확도: 1152/10000 (12%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2l8netOuwHDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}